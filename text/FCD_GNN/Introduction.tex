\documentclass[FCD_GNN.tex]{subfiles}

\begin{document}
\chapter{Introduction}

This chapter first highlights the importance of epilepsy detection and discusses the limitations of existing methods. 
It outlines the main objectives of the thesis and its research contributions. 
Finally, the chapter concludes with an overview of the thesis structure.

\section{Motivation}
% Automatic detection of tumors using medical imaging has been widely studied across different internal organs.
% Recent advances in deep learning and transformer-based approaches have led to impressive results in the diagnosis of lung cancer~\cite{Durgam2025LungCancer}, brain tumor~\cite{Abdusalomov2023BrainTumor}, kidney \ac{ct}~\cite{Sharma2025KidneyCT}, and breast cancer~\cite{Mehmood2025BreastCancer}. 
% These studies demonstrate the potential of modern computer vision techniques to achieve clinically significant results in various diagnostic tasks.  

% However, the detection of epileptogenic lesions, in particular \ac{fcd}, remains a much more difficult task. 
% Unlike tumors, such lesions usually do not change in size over time, and their inconspicuous appearance makes it difficult even for experienced neuroradiologists to identify them. 
% In addition, the lack of large publicly available annotated datasets has significantly slowed progress in this area. 
% To address this problem, within the framework of the \ac{meld} project~\cite{Ripart2025MELD} a large-scale collaborative dataset has recently been created and graph neural networkâ€“based approaches have been developed for epileptogenic lesion detection~\cite{Ripart2025MELD}. 
% Although this is the most advanced solution to date, performance remains limited, underscoring the continued complexity of this task.

% At the same time, \textit{text-guided} and \textit{multimodal approaches} have gained momentum in medical image analysis. 
% Integrating textual prompts or language-guided embeddings with visual features has been shown to substantially enhance segmentation accuracy in chest X-ray infection detection~\cite{Zhong2023Ariadne}, 
% language-guided multi-level alignments~\cite{Li2024LGMSeg}, organ-aware segmentation~\cite{Zhang2025OrganAware}, multimodal tumor analysis~\cite{Li2025Mulmodseg}, 
% and pneumothorax segmentation~\cite{Huemann2024ConTEXTualNet}. 
% These advances demonstrate that textual annotations, ranging from atlas-based region names to descriptive clinical reports, provide valuable complementary information. 
% By projecting textual and visual features into a shared latent space, such information can be effectively aligned and leveraged to enhance model performance.

Automatic detection of tumors using medical imaging has been widely studied across different internal organs.
Recent advances in deep learning and transformer-based approaches have led to impressive results in tumor detection tasks, including lung cancer~\cite{Durgam2025LungCancer}, brain tumors~\cite{Abdusalomov2023BrainTumor}, kidney tumors on \ac{ct} imaging~\cite{Sharma2025KidneyCT}, and breast cancer~\cite{Mehmood2025BreastCancer}. 
These studies demonstrate the potential of modern computer vision techniques to achieve clinically significant results in various diagnostic tasks.  

However, the detection of epileptogenic lesions, in particular \ac{fcd}, remains substantially more challenging.
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{pictures/FCD_example.png}
    \caption{Typical features of focal cortical dysplasias (FCDs) visible in MRI~\cite{walger2023ai_fcd}}
    \label{unseen_fcds}
\end{figure}

Unlike tumors, which often show progressive growth and well--defined boundaries, epileptogenic lesions typically remain stable in size and present with subtle imaging features, as illustrated in Fig.~\ref{unseen_fcds}, complicating their identification even for trained neuroradiologists~\cite{walger2023ai_fcd}.
Earlier approaches~\cite{wagner2011morphometric_fcd, dev2019automatic_fcd, house2021automated_fcd} to automated FCD detection mainly used volumetric convolutional neural networks trained on 3D MRI data, such as T1-weighted and FLAIR images. 
However, these methods were usually developed using relatively small datasets, often including only a few dozen to a few hundred patients, which limited their reliability and ability to generalize to unseen data. 
In addition, volumetric CNN-based approaches do not directly model the cortical surface or its shape, even though FCD-related abnormalities mainly affect the cortex. 
In contrast, the \ac{meld} project~\cite{Ripart2025MELD} uses a surface-based representation of the cortex and applies graph neural networks to model cortical structure and local relationships, allowing the use of large multi-center datasets and addressing important limitations of earlier volumetric methods.
Although this represents one of the most advanced solutions to date, performance remains limited, underscoring the continued complexity of the detection task.

At the same time, recent progress in text-guided and multimodal learning suggests that combining visual information with textual descriptions may help models focus on clinically relevant anatomical regions.  
In the context of epileptogenic lesion detection, such textual information can reflect prior clinical knowledge derived from examinations other than MRI, such as EEG findings or seizure semiology.  
For tasks with limited training data, textual annotations can therefore serve as an additional source of structure by guiding the model toward regions that are clinically suspected, even when MRI findings are subtle.  
This motivates investigating whether integrating such information, even in a coarse form (e.g., hemisphere or lobe labels), can help compensate for the scarcity of annotated datasets and improve detection performance.

In this thesis, we build upon the surface-based feature maps produced by the pretrained MELD model, which represent the cortical surface as a sparse graph.  
Given this graph-based representation, a natural next step is to investigate whether additional \ac{gnn} layers can further improve lesion detection by aggregating information across larger neighborhoods on the cortical surface.  
Understanding the benefits and limitations of such graph-based aggregation is particularly important in sparse settings, where capturing long-range context may directly influence lesion detection.

\section{Aims of the Thesis}
The main objective of this thesis is to investigate how the integration of textual and visual information 
can improve the accuracy of epileptogenic lesion detection. 
Several research questions were formulated:

\begin{enumerate}
    \item Do incorporating textual descriptions from anatomical atlases influence the accuracy of lesion segmentation?
    \item Can competitive performance be achieved using only partial atlas information (e.g., hemisphere or lobe labels)?
    \item What is the impact of integrating additional \ac{gnn} blocks with \ac{meld}-based representations on segmentation quality?
\end{enumerate}

We systematically evaluate the impact of different types of textual information, as well as alternative strategies 
for combining visual features, including the integration of additional \ac{gnn} layers. 
We further analyze how these design choices influence segmentation performance, 
demonstrating that the joint integration of textual and visual features can enhance both the accuracy 
and the sensitivity of epileptogenic lesion detection.

\section{Contributions}

The main contributions of this thesis can be summarized as follows:

\begin{enumerate}    
    \item Introduced a state-of-the-art multimodal model for epileptogenic lesion detection that integrates surface-based visual features with textual information.
    \item Conducted a systematic evaluation of design choices related to graph-based feature aggregation, including different configurations of GNN blocks.
    \item Assessed the effect of multiple types of textual descriptions (full atlas annotations, hemisphere and lobe labels, etc.) on model accuracy and sensitivity.
    \item Delivered comprehensive documentation and usage guidelines for the implemented methods.
    \item Implemented a user-friendly interface that supports different pretrained models and enables interactive visualization of predictions.
\end{enumerate}

\section{Thesis structure}
The structure of this thesis is organized as follows:
\begin{enumerate}
    \item Chapter~\ref{chapter:Related_works} reviews prior work on \acs{fcd} detection and text-guided medical image segmentation, focusing on architectural choices, fusion strategies, and open limitations that motivate our approach.

    \item Chapter~\ref{chapter:Method} presents the proposed multimodal segmentation framework for epileptogenic lesion detection, detailing the surface-based visual features (from MELD preprocessing), the \acs{gnn} block, \acs{llm} textual embeddings, and their integration within the GuideDecoder (with HexUnpool and SpiralConv adaptations).

    \item Chapter~\ref{chapter:Dataset} describes the Bonn and MELD datasets, FreeSurfer-based feature extraction and harmonization, the data-augmentation pipeline, and the variants of atlas-derived textual descriptions used in our study.

    \item Chapter~\ref{chapter:Experiments} details the experimental setup (losses, metrics, and implementation specifics) and reports the main results: baseline comparisons against MELD, the effect of linking different numbers of MELD feature stages to the \acs{gnn} block, as well as experiments with mixed-text settings.

    \item Chapter~\ref{chapter:Discussion} discusses the findings, emphasizing trade-offs between sensitivity and precision, limitations of the current study, and implications for clinical applicability.

    \item Finally, Chapter~\ref{chapter:Conclusion} summarizes key insights, outlines the limitations, and proposes directions for future research.
\end{enumerate}
\end{document}
