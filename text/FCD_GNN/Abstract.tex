\documentclass[FCD_GNN.tex]{subfiles}

\begin{document}
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Numerous methods have been developed for tumor detection in medical images, demonstrating the effectiveness of deep learning across a wide range of diagnostic tasks. 
However, the detection of \ac{fcd} is considerably more challenging. 
In contrast to tumors, these lesions do not exhibit progressive growth, often lack clear visual boundaries, and are characterized by subtle and heterogeneous imaging patterns. 
As a result, the sensitivity of existing automated detection methods remains relatively low, even for state-of-the-art approaches such as MELD, which currently represents one of the best-performing frameworks in this domain. 
In addition, publicly available annotated datasets for \ac{fcd} are highly limited. 

To address these limitations, this thesis proposes a novel multimodal segmentation framework that combines surface-based visual features with text-based inputs that guide the segmentation process. 
Experimental results showed that the proposed approach improves both detection accuracy and sensitivity compared to the MELD baseline. 
To further illustrate the practical utility of the proposed method, a web-based interface was implemented, enabling access to all model variants and their corresponding predictions.

\end{document}